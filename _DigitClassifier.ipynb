{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Handwritten Digit Classifier \u2013 \n",
        "\n",
        "This notebook runs training and inference for the Data Science Intern Mini Project.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install torch torchvision scikit-learn numpy\n",
        "!mkdir -p src models dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%writefile src/__init__.py\n",
        "# Makes src a Python package so we can run: python -m src.train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%writefile src/train.py\n",
        "import argparse, os, random, numpy as np, torch, torch.nn as nn, torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n\ndef set_seed(seed=42):\n    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nclass SmallCNN(nn.Module):\n    def __init__(self, img_size=64):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n        self.pool = nn.MaxPool2d(2, 2)\n        with torch.no_grad():\n            x = torch.zeros(1, 1, img_size, img_size)\n            x = self.pool(F.relu(self.conv2(F.relu(self.conv1(x)))))\n            flat = x.numel()\n        self.fc1 = nn.Linear(flat, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv2(F.relu(self.conv1(x)))))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\ndef make_loaders(data_dir, img_size, batch=64, seed=42):\n    aug = transforms.Compose([\n        transforms.Grayscale(),\n        transforms.Resize((img_size, img_size)),\n        transforms.RandomRotation(10),\n        transforms.ColorJitter(brightness=0.2),\n        transforms.ToTensor()\n    ])\n    plain = transforms.Compose([\n        transforms.Grayscale(),\n        transforms.Resize((img_size, img_size)),\n        transforms.ToTensor()\n    ])\n    full_aug = datasets.ImageFolder(data_dir, transform=aug)\n    full_plain = datasets.ImageFolder(data_dir, transform=plain)\n    idx = np.arange(len(full_aug))\n    y = np.array(full_aug.targets)\n    tr, tmp = train_test_split(idx, test_size=0.30, stratify=y, random_state=seed)\n    tmp_y = y[tmp]\n    va, te = train_test_split(tmp, test_size=0.5, stratify=tmp_y, random_state=seed)\n    tr_set = Subset(full_aug, tr)\n    va_set = Subset(full_plain, va)\n    te_set = Subset(full_plain, te)\n    return (\n        DataLoader(tr_set, batch_size=batch, shuffle=True),\n        DataLoader(va_set, batch_size=batch),\n        DataLoader(te_set, batch_size=batch),\n    )\n\ndef train_model(model, loader, device, epochs=5):\n    opt = optim.Adam(model.parameters(), lr=0.001)\n    loss_fn = nn.CrossEntropyLoss()\n    for e in range(epochs):\n        model.train()\n        total = 0.0\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            opt.zero_grad()\n            out = model(x)\n            loss = loss_fn(out, y)\n            loss.backward()\n            opt.step()\n            total += loss.item()\n        print(f\"Epoch {e+1}/{epochs}, Loss = {total/len(loader):.4f}\")\n\ndef evaluate(model, loader, device, name=\"Val\"):\n    model.eval()\n    preds, trues = [], []\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            p = model(x).argmax(1)\n            preds += p.cpu().numpy().tolist()\n            trues += y.cpu().numpy().tolist()\n    acc = accuracy_score(trues, preds)\n    f1 = f1_score(trues, preds, average=\"macro\")\n    cm = confusion_matrix(trues, preds)\n    print(f\"{name} Accuracy = {acc:.4f} | F1 = {f1:.4f}\")\n    print(f\"{name} Confusion Matrix:\\n{cm}\")\n    return acc, f1, cm\n\ndef misclassified(model, loader, device, maxn=5):\n    model.eval()\n    out = []\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            p = model(x).argmax(1)\n            for i in range(len(y)):\n                if p[i] != y[i]:\n                    out.append((int(y[i]), int(p[i])))\n                    if len(out) >= maxn:\n                        return out\n    return out\n\ndef main():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--data\", default=\"./dataset\")\n    ap.add_argument(\"--epochs\", type=int, default=15)\n    ap.add_argument(\"--img_size\", type=int, default=64)\n    args = ap.parse_args()\n\n    set_seed(42)\n    os.makedirs(\"models\", exist_ok=True)\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    train_loader, val_loader, test_loader = make_loaders(args.data, args.img_size)\n\n    baseline = SmallCNN(args.img_size).to(device)\n    print(\"Training baseline model...\")\n    train_model(baseline, train_loader, device, epochs=5)\n    evaluate(baseline, val_loader, device, \"Baseline Val\")\n    evaluate(baseline, test_loader, device, \"Baseline Test\")\n    torch.save(baseline.state_dict(), \"models/baseline.pt\")\n\n    print(\"\\nTraining improved ResNet18...\")\n    net = models.resnet18(pretrained=False)\n    net.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n    net.fc = nn.Linear(net.fc.in_features, 10)\n    net = net.to(device)\n    train_model(net, train_loader, device, epochs=args.epochs)\n    evaluate(net, val_loader, device, \"Improved Val\")\n    evaluate(net, test_loader, device, \"Improved Test\")\n    torch.save(net.state_dict(), \"models/best.pt\")\n    print(\"Misclassified examples (true, pred):\", misclassified(net, test_loader, device))\n\nif __name__ == \"__main__\":\n    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%writefile src/infer.py\n",
        "import argparse, os, glob, csv, torch, torch.nn as nn\nfrom torchvision import models, transforms\nfrom PIL import Image\n\ndef build_model():\n    m = models.resnet18(pretrained=False)\n    m.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n    m.fc = nn.Linear(m.fc.in_features, 10)\n    return m\n\ndef infer(images, weights, out, img_size=64):\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    model = build_model().to(device)\n    model.load_state_dict(torch.load(weights, map_location=device))\n    model.eval()\n    tfm = transforms.Compose([\n        transforms.Grayscale(),\n        transforms.Resize((img_size, img_size)),\n        transforms.ToTensor(),\n    ])\n    files = []\n    for ext in (\"*.png\", \"*.jpg\", \"*.jpeg\"):\n        files += glob.glob(os.path.join(images, ext))\n    rows = []\n    with torch.no_grad():\n        for f in sorted(files):\n            img = Image.open(f).convert(\"L\")\n            x = tfm(img).unsqueeze(0).to(device)\n            p = model(x).argmax(1).item()\n            rows.append([os.path.basename(f), p])\n            print(f\"{f} -> {p}\")\n    with open(out, \"w\", newline=\"\") as fp:\n        writer = csv.writer(fp)\n        writer.writerow([\"filename\", \"predicted\"])\n        writer.writerows(rows)\n    print(\"Saved predictions to\", out)\n\nif __name__ == \"__main__\":\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--images\", required=True)\n    ap.add_argument(\"--weights\", required=True)\n    ap.add_argument(\"--out\", default=\"preds.csv\")\n    ap.add_argument(\"--img_size\", type=int, default=64)\n    a = ap.parse_args()\n    infer(a.images, a.weights, a.out, a.img_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Upload your `dataset.zip` with folders 0\u20139, then unzip into `./dataset`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # upload dataset.zip\n",
        "!unzip -q dataset.zip -d ./dataset\n",
        "!ls dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!python -m src.train --data ./dataset --epochs 15 --img_size 64\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!mkdir -p sample\n",
        "# upload some sample digit images into ./sample if you like\n",
        "!python -m src.infer --images ./sample --weights ./models/best.pt --out preds.csv\n",
        "!head preds.csv\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
